Final Report
Arahman Gulaid
CS 4375.5U1 - Introduction to Machine Learning
Assignment 1
==================================================================

-> first part: linear Regression (part1.py)



Dataset Used:
  - Air Quality Dataset from UCI ML Repository
  - Public link: https://raw.githubusercontent.com/maangulaid/cs4375-linear-regression-Arahman/main/AirQualityUCI.csv

Preprocessing Summary:
 -Removed unnamed/missing columns
 - Dropped null values
 - drotted or removed the Date and time
 - Standardized features using StandardScaler

Parameter:
  - Best Learning Rate -----> 0.17
  - Iterations       -------> 1000
  - Final Train MSE  -------> 1.8350
  - Final Test MSE   -------> 1.7430
  - R² Score         -------> 0.9991
  - Explained Var    -------> 0.9991

Evaluation:
  - Model converged well with minimal error.
  - Training loss decreased steadily (see mse_plot.png).
  - High R² and Explained Variance show good generalization.

Question:
Are you satisfied that the pack-age has found the best solution?. How can you check?. Explain?

Answer:

Yes, I am satisfied the best solution was found.
The error metrics are consistent, and no overfitting is evident.
Multiple trials were conducted for tuning all the trails are in Trail_log.txt


---------------------------------------------------------------------------------------------------------------------------------------------
Part2 : Linear Regression using Scikit-learn



SGDRegressor Configuration:
  - Learning Rate (eta0)-------> 0.17
  - Max Iterations      -------> 1000
  - Loss Function       -------> Squared Error
  - Penalty             -------> None 

Results:
  - Final Train MSE     -------> 1.4617
  - Final Test MSE      -------> 1.3713
  - R² Score            -------> 0.9994
  - Explained Variance  -------> 0.9994

Question:
Are you satisfied that the pack-age has found the best solution?. How can you check?. Explain?

Answer:
  Yes, the package found an optimal solution.
  Results are slightly improved compared to manual GD implementation.
  Scikit-learn leverages stochastic updates, which are more efficient.












here is more log trials:




# CS4375 Assignment 1 - Parameter Tuning Trial Log
# Format: Learning Rate, Iterations, Final Train MSE, Final Test MSE

# --- Part 1: Manual Gradient Descent ---
0.01,1000,4.1429,3.9229
0.02,1000,3.0237,2.8548
0.05,1000,2.5107,2.3869
0.06,1000,2.4266,2.3084
0.08,1000,2.2819,2.1713
0.1,1000,2.1574,2.0523
0.12,1000,2.0491,1.9484
0.19,1000,358798833908069106525502793513867466059708747580597888620982822594475146392775045033344421068800.0000,477559274979613257116977683606660063472466665890483376478307577949772665842831908648475084980224.0000
0.17,1000,1.8350,1.7430
0.17,1000,1.8350,1.7430
0.17,1000,1.8350,1.7430
0.17,100,3.1872,2.9979
0.17,10000,1.3101,1.2409
0.17,1000,1.8350,1.7430
0.01,1000,1.4617,1.37130.17,500,2.2496,2.1400
0.17,20000,1.3101,1.2409
0.17,500,2.2496,2.1400
0.17,400,2.3664,2.2510
0.17,10,204.7087,175.6321
0.17,900,1.8998,1.8051
0.17,9000,1.3102,1.2410
0.17,90000,1.3101,1.2409
0.17,1000,1.8350,1.7430



#Part2.py
0.01,1000,1.4617,1.3713
0.17,1000,1418942836857931051302912.0000,1489555654533454105673728.0000
0.17,1000,1418942836857931051302912.0000,1489555654533454105673728.0000
0.3,1000,6281715145694329842958336.0000,6814487212201641024421888.0000
0.09,1000,886293933721673512517632.0000,958976399383273597304832.0000
0.05,1000,160939131284093340221440.0000,177508981863588005150720.0000
0.02,1000,48788451189187311304704.0000,53527037847928504844288.0000
0.01,1000,1.4617,1.3713
0.02,1000,48788451189187311304704.0000,53527037847928504844288.0000
0.9,1000,32123214031454815687540736.0000,34078490913673668773019648.0000
0.1,1000,1106220290309721197379584.0000,1197335111455414440427520.0000
0.01,400,1.4617,1.3713
0.01,500,1.4617,1.3713
0.01,6000,1.4617,1.3713
0.01,900,1.4617,1.3713
0.01,10,1.7001,1.5956
0.01,1,2.7257,2.5920
0.01,100000,1.4617,1.3713
0.01,98,1.4617,1.3713
0.01,1000,1.4617,1.3713
0.01,1000,1.4617,1.3713
0.01,1000,1.4617,1.3713
